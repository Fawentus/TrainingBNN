----------------------------------------------------------------
        Layer (type)               Output Shape         Param #
================================================================
BinaryInternalLinear-1                  [-1, 512]     102,760,960
       BatchNorm1d-2                  [-1, 512]           1,024
        Activation-3                  [-1, 512]               0
      BinaryLinear-4                  [-1, 512]               0
BinaryInternalLinear-5                  [-1, 512]         262,656
       BatchNorm1d-6                  [-1, 512]           1,024
        Activation-7                  [-1, 512]               0
      BinaryLinear-8                  [-1, 512]               0
BinaryInternalLinear-9                  [-1, 128]          65,664
      BatchNorm1d-10                  [-1, 128]             256
       Activation-11                  [-1, 128]               0
     BinaryLinear-12                  [-1, 128]               0
BinaryInternalLinear-13                   [-1, 10]           1,290
BinaryLinearOutput-14                   [-1, 10]               0
================================================================
Total params: 103,092,874
Trainable params: 103,092,874
Non-trainable params: 0
----------------------------------------------------------------
Input size (MB): 0.77
Forward/backward pass size (MB): 0.04
Params size (MB): 393.27
Estimated Total Size (MB): 394.07
----------------------------------------------------------------
PARAM: torch.Size([512, 200704]) Parameter containing:
tensor([[-1., -1., -1.,  ..., -1., -1., -1.],
        [-1., -1., -1.,  ..., -1., -1., -1.],
        [-1., -1., -1.,  ..., -1., -1., -1.],
        ...,
        [-1., -1., -1.,  ..., -1., -1., -1.],
        [-1., -1., -1.,  ..., -1., -1., -1.],
        [-1., -1., -1.,  ..., -1., -1., -1.]], device='cuda:0',
       requires_grad=True)
PARAM: torch.Size([512]) Parameter containing:
tensor([  30881.6016,   25496.5977,   24764.8105,   30881.5742,   24764.8145,
          30881.5957,   30881.5918,   30881.5859,   25496.5957,   25496.5879,
          30881.6016,   30881.5840,   30881.5957,   24764.8066,   24764.8105,
          28525.5820,   30881.6016,   30881.6016,   30881.5820,   25496.5859,
          24764.8066,   30881.5957,   30881.5957, -105361.3906,   24764.8066,
          24764.8145,   30881.6367,   25496.5879,   28525.5918,   30881.5840,
          24764.8105,   30881.5820,   25496.5957,   30881.6621,   24764.8184,
          30881.6016,   25496.5957,   24764.8145,   30881.5918,   24764.8105,
          25496.5957,   30881.6016,   30881.6484,   30881.6465,   30881.5840,
          24764.8105,   30881.5859,   30881.5957,   24764.8145,   24764.8105,
          30881.6465,   24764.8105,   24764.8105,   25496.5977,   30881.6016,
          25496.5859,   25496.5977,   30881.6016,   30881.5918,   30881.6016,
          25496.5957,   25496.5879,   28525.5820,   24764.8105,   30881.5859,
          24764.8066,   24764.8145,   30881.6016,   25496.5859,   30881.5840,
          30881.6016,   24764.8066,    9341.5850,   30881.5723,   30881.5742,
          24764.8105,   24764.8105,   25496.5957,   24764.8105,    5862.8857,
          30881.6016,   24764.8066,    9341.5723,   24764.8145,   24764.8105,
          30881.6016,   30881.5957,   30881.5117,   30881.5840,   28525.5898,
          25496.5977,   24764.8066,   24764.8184,   28525.5898,   25496.5859,
          30881.5742,   24764.8105,   24764.8105,   24764.7539,   30881.5957,
          28525.5820,   30881.6484,   30881.6484,   24764.8184,   30881.6016,
          30881.6367,   24764.8066,   24764.8066,   25496.5879,   24764.8184,
          30881.5840,   24764.8066,   30881.6016,   25496.5957,   30252.5215,
          30881.5957,   30881.5742,   30881.5957,   30881.5957,   30881.6016,
          25496.5859,   30881.5215,   24764.8066,   24764.8105,   24764.8105,
          24764.8066,   30881.5918,   24764.8184,   25496.5977,   30881.5957,
          30881.6016,   28525.5898,    9341.5869,   28525.5820,   30881.6016,
          30881.5742,   30881.6016,   30881.6367,   24764.8184,   25496.5859,
          30881.5859,   30881.5859,   30881.6465,   30881.6367,   24764.8184,
          24764.8105,   30881.5957,   25496.5879,    9341.5723,   24764.8105,
          24764.8105,   24764.8066,   25496.8047,   24764.8145,   30881.6016,
          30881.5918,   24764.8066,   30881.5957,   30881.6016,   25496.5957,
          30881.5918,   28525.5820,   30881.5957,   30881.6465,   24764.8145,
          30881.6016,   30881.5957,   24764.8145,   24764.8066,   30881.5742,
          25496.5859,   30881.6465,   24764.8105,   25496.5977,   28525.5898,
          24764.8184,   24764.8066,   24764.8066,   30881.5840,   28525.5820,
          24764.8184,   30881.6016,   30881.5840,   30881.6016,   24764.8066,
          30881.5918,   25496.5859,   24764.8066,   24764.8105,   30881.6016,
          30881.6016,   24764.8105,   30881.6016,   24764.8066,   28525.5918,
          24764.8066,   30881.5840,   30881.5957,   30881.5957,   24764.8066,
          30881.5957,   30881.5918,   30881.5840,   30881.5742,   30881.6016,
          30881.5957,   30881.5918,   24764.8145,   24764.8145,   30881.6016,
          24764.8105,   28525.5820,   25496.5859,   30881.6016,   24764.8066,
          24764.8066,   30881.6367,   24764.8105,   30881.6016,   24764.8066,
          25496.5859,   24764.8105,   30881.5918,   30881.6367,   30881.6367,
          25496.5957,   30881.6016,   24764.8066,   30881.5918,   24764.8184,
          24764.8105,   30881.5918,   30881.5840,   24764.8066,   30881.5840,
          25496.5879,   30881.5820,   25496.5859,   30881.5840,   30881.5957,
          24764.8184,   30881.5742,   30881.5957,   24764.8066,   25496.5879,
          24764.8105,   30881.5957,   30881.6465,   24764.8184,   24764.8066,
          30881.6016,   30881.5859,   24764.8145,   25496.5859,   25496.5859,
          25496.5859,   30881.5957,   30881.6016,   24764.7266,   30881.6582,
          30881.5918,   24764.8184,   24764.8105,   24764.8066,   24764.8105,
          25496.5859,   30881.5957,   30881.5957,   30881.5840,   24764.8066,
          30881.6367,   25496.5977,   24764.8105,   25496.5859,   24764.8105,
          24764.7480,   30881.6016,   24764.8105,   24764.8184,   24764.8105,
          30881.5957,   28525.5918,   30881.6016,   24764.8145,   30881.6016,
          24764.7266,   30881.6758,   30881.7109,   30881.5957,   24764.8184,
          24764.8066,   30881.6016,   30881.5918,   30881.5840,   24764.7480,
          24764.8105,   30881.6016,   30881.6016,   28525.5918,   30881.6016,
          30881.6016,   25496.5879,   24764.8145,   25496.5859,   28525.5918,
        -105361.3906, -105361.3906,   30881.6016,   24764.7539,   30881.5918,
          24764.8184,   30881.6465,   30881.5859,   30881.6484,   30881.5957,
          24764.8145,   25496.5957,   30881.6016,   24764.8066,   30881.6016,
          25496.5879,   28525.5898,   30881.6016,   30881.6016,   30881.5742,
          24764.8105,   25496.5957,   24764.8105,   24764.8105,   24764.7480,
          24764.8105,   25496.5957,   30881.5957,   25496.5977,   30881.5840,
          24764.8066,   30881.6016,   24764.8066,   30881.6016,   25496.5977,
          30881.6016,   30881.6367,   25496.5859,   30881.6016,   28525.5918,
          30881.5957,   24764.7539,   30881.6367,   30881.5957,   30252.5117,
          25496.5879,   24764.8105,   30881.6016,   24764.8145,   24764.8145,
          24764.8184,   30881.6016,   25496.5859,   30881.5957,   30881.5859,
          25496.5957,   25496.5859,   24764.8066,   24764.8066,   30881.5918,
          24764.8105,   30881.5957,   30252.5117,   30881.5840,   24764.8105,
          28525.5918,   24764.8184,   30881.6016,   30881.5742,   30881.5957,
          30881.6484,   30881.6699,   30881.6016,   30881.5957,   30881.5957,
          30881.5918,   24764.8066,   30881.6016,   30881.6699,   30881.5918,
          24764.8184,   24764.8145,   24764.8145,   24764.8066,   30881.6367,
          24764.8184,   30881.5957,   25496.5859,   30881.6016,   30881.5957,
          25496.5879,   30881.6016,   24764.8066,   25496.5859,   30881.6016,
          24764.8145,   24764.8066,   24764.8105,   24764.8145,   24764.8105,
          28525.5820,   30881.5742,   24764.8066,   25496.5977,   30881.6016,
          30881.6367,   30881.5742,   24764.8066,   24764.8066,   30881.5840,
          24764.8066,   25496.5957,   30881.5918,   30881.6016,   24764.8145,
          25496.5957,   25496.5859,   24764.8145,   24764.8105,   30881.6016,
          28525.5918,   24764.8105,   30881.6016,   30881.5840,   24764.8105,
          24764.8105,   24764.8105,   30881.5957,   24764.8105,   24764.8066,
          30881.6484,   24764.8105,   30881.5840,    9341.5723,   24764.7305,
          25496.5859,   24764.8066,   30881.5742,   30881.5742,   30881.6016,
          25496.5859,   30881.6016,   24764.7305,   24764.8105,   24764.7539,
          30881.5957,   24764.8066,   30881.6660,   30881.6016,   25496.5859,
          24764.7539,   30881.6016,   24764.8066,   24764.8066,   30252.5117,
          30881.5957,   30881.5840,   30881.7363,   24764.8066,   24764.8066,
          24764.8105,   30881.5859,   30881.6016,   25496.5859,   28525.5820,
          24764.8105,   24764.8145,   25496.5859,   24764.8105,   30881.5840,
          30881.6523,   30881.5957,   30881.5957,   24764.8145,   24764.8066,
          25496.5859,   30881.5840,   24764.8066,   30881.5859,   30881.5117,
          24764.8066,   30881.5918,   30881.5918,   30881.5957,   24764.8066,
          25496.5859,   30881.5723,   30881.6016, -384864.0000,   30881.5918,
          30881.6367,   30881.5957,   30881.5840,   30881.5918,   24764.8145,
          24764.8105,   24764.8184,   30881.6621,   25496.5957,   25496.5977,
          30881.6016,   30881.5918,   30881.5957,   30881.5918,   30881.5840,
          30881.6582,   30881.5918], device='cuda:0', requires_grad=True)
PARAM: torch.Size([512]) Parameter containing:
tensor([ -8.8821,  -6.7662, -11.0898,  -8.8821, -11.0898,  -8.8821,  -8.8821,
         -8.8821,  -6.7662,  -6.7662,  -8.8821,  -8.8821,  -8.8821, -11.0898,
        -11.0898,  -7.2758,  -8.8821,  -8.8821,  -8.8821,  -6.7662, -11.0898,
         -8.8821,  -8.8821, -15.7835, -11.0898, -11.0898,  -8.8821,  -6.7662,
         -7.2758,  -8.8821, -11.0898,  -8.8821,  -6.7662,  -8.8821, -11.0898,
         -8.8821,  -6.7662, -11.0898,  -8.8821, -11.0898,  -6.7662,  -8.8821,
         -8.8821,  -8.8821,  -8.8821, -11.0898,  -8.8821,  -8.8821, -11.0898,
        -11.0898,  -8.8821, -11.0898, -11.0898,  -6.7662,  -8.8821,  -6.7662,
         -6.7662,  -8.8821,  -8.8821,  -8.8821,  -6.7662,  -6.7662,  -7.2758,
        -11.0898,  -8.8821, -11.0898, -11.0898,  -8.8821,  -6.7662,  -8.8821,
         -8.8821, -11.0898, -13.1139,  -8.8821,  -8.8821, -11.0898, -11.0898,
         -6.7662, -11.0898, -11.5076,  -8.8821, -11.0898, -13.1139, -11.0898,
        -11.0898,  -8.8821,  -8.8821,  -8.8821,  -8.8821,  -7.2758,  -6.7662,
        -11.0898, -11.0898,  -7.2758,  -6.7662,  -8.8821, -11.0898, -11.0898,
         -6.6744,  -8.8821,  -7.2758,  -8.8821,  -8.8821, -11.0898,  -8.8821,
         -8.8821, -11.0898, -11.0898,  -6.7662, -11.0898,  -8.8821, -11.0898,
         -8.8821,  -6.7662,  -7.8478,  -8.8821,  -8.8821,  -8.8821,  -8.8821,
         -8.8821,  -6.7662,  -8.8821, -11.0898, -11.0898, -11.0898, -11.0898,
         -8.8821, -11.0898,  -6.7662,  -8.8821,  -8.8821,  -7.2758, -13.1139,
         -7.2758,  -8.8821,  -8.8821,  -8.8821,  -8.8821, -11.0898,  -6.7662,
         -8.8821,  -8.8821,  -8.8821,  -8.8821, -11.0898, -11.0898,  -8.8821,
         -6.7662, -13.1139, -11.0898, -11.0898, -11.0898, -10.9980, -11.0898,
         -8.8821,  -8.8821, -11.0898,  -8.8821,  -8.8821,  -6.7662,  -8.8821,
         -7.2758,  -8.8821,  -8.8821, -11.0898,  -8.8821,  -8.8821, -11.0898,
        -11.0898,  -8.8821,  -6.7662,  -8.8821, -11.0898,  -6.7662,  -7.2758,
        -11.0898, -11.0898, -11.0898,  -8.8821,  -7.2758, -11.0898,  -8.8821,
         -8.8821,  -8.8821, -11.0898,  -8.8821,  -6.7662, -11.0898, -11.0898,
         -8.8821,  -8.8821, -11.0898,  -8.8821, -11.0898,  -7.2758, -11.0898,
         -8.8821,  -8.8821,  -8.8821, -11.0898,  -8.8821,  -8.8821,  -8.8821,
         -8.8821,  -8.8821,  -8.8821,  -8.8821, -11.0898, -11.0898,  -8.8821,
        -11.0898,  -7.2758,  -6.7662,  -8.8821, -11.0898, -11.0898,  -8.8821,
        -11.0898,  -8.8821, -11.0898,  -6.7662, -11.0898,  -8.8821,  -8.8821,
         -8.8821,  -6.7662,  -8.8821, -11.0898,  -8.8821, -11.0898, -11.0898,
         -8.8821,  -8.8821, -11.0898,  -8.8821,  -6.7662,  -8.8821,  -6.7662,
         -8.8821,  -8.8821, -11.0898,  -8.8821,  -8.8821, -11.0898,  -6.7662,
        -11.0898,  -8.8821,  -8.8821, -11.0898, -11.0898,  -8.8821,  -8.8821,
        -11.0898,  -6.7662,  -6.7662,  -6.7662,  -8.8821,  -8.8821, -11.0898,
         -8.8821,  -8.8821, -11.0898, -11.0898, -11.0898, -11.0898,  -6.7662,
         -8.8821,  -8.8821,  -8.8821, -11.0898,  -8.8821,  -6.7662, -11.0898,
         -6.7662, -11.0898,  -6.6744,  -8.8821, -11.0898, -11.0898, -11.0898,
         -8.8821,  -7.2758,  -8.8821, -11.0898,  -8.8821, -11.0898,  -8.8821,
         -8.8821,  -8.8821, -11.0898, -11.0898,  -8.8821,  -8.8821,  -8.8821,
         -6.6744, -11.0898,  -8.8821,  -8.8821,  -7.2758,  -8.8821,  -8.8821,
         -6.7662, -11.0898,  -6.7662,  -7.2758, -15.7835, -15.7835,  -8.8821,
         -6.6744,  -8.8821, -11.0898,  -8.8821,  -8.8821,  -8.8821,  -8.8821,
        -11.0898,  -6.7662,  -8.8821, -11.0898,  -8.8821,  -6.7662,  -7.2758,
         -8.8821,  -8.8821,  -8.8821, -11.0898,  -6.7662, -11.0898, -11.0898,
         -6.6744, -11.0898,  -6.7662,  -8.8821,  -6.7662,  -8.8821, -11.0898,
         -8.8821, -11.0898,  -8.8821,  -6.7662,  -8.8821,  -8.8821,  -6.7662,
         -8.8821,  -7.2758,  -8.8821,  -6.6744,  -8.8821,  -8.8821,  -7.8478,
         -6.7662, -11.0898,  -8.8821, -11.0898, -11.0898, -11.0898,  -8.8821,
         -6.7662,  -8.8821,  -8.8821,  -6.7662,  -6.7662, -11.0898, -11.0898,
         -8.8821, -11.0898,  -8.8821,  -7.8478,  -8.8821, -11.0898,  -7.2758,
        -11.0898,  -8.8821,  -8.8821,  -8.8821,  -8.8821,  -8.8821,  -8.8821,
         -8.8821,  -8.8821,  -8.8821, -11.0898,  -8.8821,  -8.8821,  -8.8821,
        -11.0898, -11.0898, -11.0898, -11.0898,  -8.8821, -11.0898,  -8.8821,
         -6.7662,  -8.8821,  -8.8821,  -6.7662,  -8.8821, -11.0898,  -6.7662,
         -8.8821, -11.0898, -11.0898, -11.0898, -11.0898, -11.0898,  -7.2758,
         -8.8821, -11.0898,  -6.7662,  -8.8821,  -8.8821,  -8.8821, -11.0898,
        -11.0898,  -8.8821, -11.0898,  -6.7662,  -8.8821,  -8.8821, -11.0898,
         -6.7662,  -6.7662, -11.0898, -11.0898,  -8.8821,  -7.2758, -11.0898,
         -8.8821,  -8.8821, -11.0898, -11.0898, -11.0898,  -8.8821, -11.0898,
        -11.0898,  -8.8821, -11.0898,  -8.8821, -13.1139, -11.0898,  -6.7662,
        -11.0898,  -8.8821,  -8.8821,  -8.8821,  -6.7662,  -8.8821, -11.0898,
        -11.0898,  -6.6744,  -8.8821, -11.0898,  -8.8821,  -8.8821,  -6.7662,
         -6.6744,  -8.8821, -11.0898, -11.0898,  -7.8478,  -8.8821,  -8.8821,
         -8.8821, -11.0898, -11.0898, -11.0898,  -8.8821,  -8.8821,  -6.7662,
         -7.2758, -11.0898, -11.0898,  -6.7662, -11.0898,  -8.8821,  -8.8821,
         -8.8821,  -8.8821, -11.0898, -11.0898,  -6.7662,  -8.8821, -11.0898,
         -8.8821,  -8.8821, -11.0898,  -8.8821,  -8.8821,  -8.8821, -11.0898,
         -6.7662,  -8.8821,  -8.8821, -22.4241,  -8.8821,  -8.8821,  -8.8821,
         -8.8821,  -8.8821, -11.0898, -11.0898, -11.0898,  -8.8821,  -6.7662,
         -6.7662,  -8.8821,  -8.8821,  -8.8821,  -8.8821,  -8.8821,  -8.8821,
         -8.8821], device='cuda:0', requires_grad=True)
PARAM: torch.Size([512]) Parameter containing:
tensor([-59998., -59998., -59943., -59960., -59999., -60000., -59997., -59997.,
        -59994., -59943., -60000., -60000., -59943., -59994., -59986., -60000.,
        -59943., -59992., -60000., -59846., -59997., -60000., -59981., -60000.,
        -59940., -59992., -60000., -60000., -59994., -59902., -59996., -59999.,
        -59941., -59996., -59943., -60000., -60000., -60000., -59998., -60000.,
        -59998., -59998., -59940., -59943., -59958., -59996., -60000., -60000.,
        -59895., -60000., -59993., -60000., -60000., -59999., -59999., -59943.,
        -59997., -60000., -59920., -59943., -59940., -59985., -60000., -59991.,
        -60000., -59835., -59996., -60000., -60000., -59975., -59999., -60000.,
        -59943., -59988., -60000., -59993., -59999., -60000., -60000., -60000.,
        -59999., -59994., -60000., -59944., -59943., -59978., -60000., -60000.,
        -59982., -59987., -60000., -60000., -59943., -59993., -59895., -60000.,
        -59995., -60000., -60000., -59993., -60000., -60000., -59963., -59864.,
        -59943., -59986., -60000., -60000., -60000., -60000., -60000., -59995.,
        -59996., -59989., -59977., -59945., -60000., -59999., -59943., -60000.,
        -59993., -60000., -59983., -60000., -59968., -59736., -59999., -60000.,
        -59954., -59971., -60000., -59969., -59986., -59943., -59943., -59854.,
        -59992., -60000., -59997., -59999., -59994., -60000., -60000., -60000.,
        -59991., -60000., -59849., -59996., -59994., -59944., -59921., -60000.,
        -59981., -60000., -59974., -60000., -59978., -59990., -59993., -59987.,
        -59995., -60000., -59938., -59996., -60000., -60000., -59953., -60000.,
        -59970., -60000., -59988., -59799., -60000., -60000., -59999., -60000.,
        -60000., -59989., -59999., -59986., -59942., -59998., -59993., -59942.,
        -59970., -59943., -59982., -60000., -59943., -59940., -60000., -59982.,
        -59998., -59998., -60000., -60000., -60000., -59943., -60000., -59999.,
        -60000., -59953., -60000., -60000., -59991., -59986., -59955., -60000.,
        -59971., -59965., -59999., -60000., -59986., -60000., -60000., -59942.,
        -60000., -59996., -60000., -59999., -60000., -59990., -59996., -60000.,
        -60000., -59931., -59943., -60000., -59925., -59996., -59965., -60000.,
        -60000., -60000., -59985., -60000., -60000., -60000., -59998., -60000.,
        -59943., -60000., -59997., -60000., -59970., -59943., -60000., -59983.,
        -59998., -59992., -59923., -59943., -60000., -59943., -59935., -59943.,
        -59971., -59845., -60000., -59943., -60000., -59992., -59943., -60000.,
        -59999., -60000., -59887., -60000., -59943., -59998., -59951., -60000.,
        -60000., -59942., -59975., -59944., -60000., -60000., -60000., -59943.,
        -60000., -60000., -60000., -59996., -60000., -60000., -59993., -59999.,
        -60000., -59978., -60000., -59998., -59943., -60000., -60000., -59988.,
        -60000., -59997., -60000., -60000., -60000., -60000., -59952., -60000.,
        -59999., -59998., -60000., -59989., -60000., -60000., -60000., -59943.,
        -59990., -59992., -59894., -60000., -60000., -59943., -59984., -60000.,
        -60000., -59936., -59940., -59977., -59985., -60000., -60000., -60000.,
        -60000., -60000., -60000., -59999., -60000., -59996., -60000., -60000.,
        -59941., -59943., -59989., -60000., -60000., -60000., -60000., -60000.,
        -59943., -59982., -59970., -59974., -59883., -59971., -60000., -59940.,
        -60000., -59997., -60000., -59982., -59993., -59999., -59999., -60000.,
        -59943., -59943., -59996., -59998., -59934., -59995., -60000., -60000.,
        -60000., -59730., -59983., -59943., -60000., -59992., -59943., -59943.,
        -59943., -60000., -60000., -60000., -60000., -60000., -60000., -59988.,
        -59982., -59979., -60000., -60000., -59987., -59995., -59865., -59943.,
        -60000., -59996., -59913., -59989., -60000., -60000., -60000., -59939.,
        -59943., -59943., -60000., -60000., -59997., -60000., -59943., -60000.,
        -59998., -59999., -60000., -59999., -59918., -60000., -60000., -59964.,
        -59995., -59989., -60000., -59993., -60000., -60000., -59971., -60000.,
        -60000., -59899., -60000., -59999., -60000., -60000., -60000., -59995.,
        -59994., -60000., -59937., -59996., -59995., -60000., -60000., -59988.,
        -60000., -59942., -59940., -60000., -59987., -60000., -59976., -59875.,
        -59943., -59987., -59961., -59995., -59999., -60000., -60000., -59988.,
        -60000., -59983., -60000., -59938., -59943., -59988., -60000., -60000.,
        -60000., -59999., -59999., -59901., -59999., -59942., -60000., -59987.,
        -60000., -59943., -59999., -59991., -60000., -60000., -59998., -59999.,
        -59999., -59762., -60000., -59999., -59943., -59993., -60000., -59986.,
        -59943., -60000., -60000., -59989., -60000., -60000., -59943., -60000.,
        -59999., -60000., -59936., -59943., -59979., -60000., -59829., -60000.,
        -60000., -59986., -60000., -60000., -60000., -60000., -59990., -59978.],
       device='cuda:0', requires_grad=True)
PARAM: torch.Size([512, 512]) Parameter containing:
tensor([[-1.,  1., -1.,  ...,  1.,  1., -1.],
        [ 1., -1.,  1.,  ..., -1., -1.,  1.],
        [ 1.,  1.,  1.,  ...,  1., -1., -1.],
        ...,
        [-1., -1.,  1.,  ...,  1., -1., -1.],
        [-1.,  1.,  1.,  ...,  1.,  1.,  1.],
        [-1.,  1., -1.,  ..., -1., -1., -1.]], device='cuda:0',
       requires_grad=True)
PARAM: torch.Size([512]) Parameter containing:
tensor([ 5.5210e+01,  7.9155e+01,  2.3176e+01,  5.5210e+01,  2.0826e+01,
         2.0909e+02,  2.6128e+00,  1.3019e+02,  1.7617e+01,  5.5210e+01,
         1.1595e+02,  1.2801e+02,  7.9155e+01,  1.1595e+02,  2.4137e+02,
         1.2800e+02,  2.4137e+02,  7.8416e+01,  1.3019e+02,  1.5605e+01,
         5.2065e+01,  2.3176e+01,  1.6004e+02,  7.8416e+01,  1.3019e+02,
         1.4154e+01,  5.9282e+01,  1.5605e+01,  2.5609e+02,  1.5605e+01,
         4.3125e+00,  1.3755e+01,  1.6004e+02,  1.0930e+02,  5.5210e+01,
         1.5034e+01,  1.7617e+01,  1.3389e+02,  7.8416e+01,  5.5210e+01,
         1.2800e+02,  1.4195e+01,  6.1139e+01,  2.5603e+02,  1.5745e+01,
         7.8416e+01,  1.7617e+01,  3.3437e+01,  1.3019e+02,  2.5078e+00,
         6.8941e+01,  7.8416e+01,  1.3755e+01,  3.0178e+00,  2.4137e+02,
         1.4195e+01,  1.9624e+02,  3.4183e+01,  6.1139e+01,  1.6004e+02,
         3.3437e+01,  1.4195e+01,  1.0930e+02,  1.3755e+01,  5.9282e+01,
         1.5034e+01,  1.9624e+02,  2.4137e+02,  1.5034e+01,  3.3437e+01,
         6.8941e+01,  2.0140e+01,  1.4058e+01,  2.4137e+02,  2.0140e+01,
         6.8941e+01,  7.8416e+01,  2.5611e+00,  3.3437e+01,  2.5040e+01,
        -3.1887e-01,  9.9645e+00,  1.6004e+02,  2.0909e+02,  1.4195e+01,
         1.3019e+02,  1.4195e+01,  2.3176e+01,  6.8941e+01,  2.5603e+02,
         7.8416e+01,  7.8416e+01,  1.9733e-04,  1.8545e+01,  1.5034e+01,
         1.3389e+02,  1.5605e+01,  1.1595e+02,  1.3389e+02,  6.8941e+01,
         1.3755e+01,  1.6004e+02,  1.1595e+02,  5.5210e+01,  1.2800e+02,
         1.3019e+02,  8.9117e-01,  1.1595e+02,  5.2065e+01,  5.9282e+01,
         2.0140e+01,  1.3389e+02,  1.7617e+01,  1.1595e+02,  2.0140e+01,
         2.4137e+02,  6.1139e+01,  1.7617e+01,  5.9282e+01,  5.5210e+01,
         1.5034e+01,  1.5034e+01,  1.4058e+01,  2.0140e+01,  1.2800e+02,
         7.8416e+01,  5.5210e+01,  2.0826e+01,  1.4058e+01,  2.0140e+01,
         2.5040e+01,  1.5034e+01,  1.6004e+02,  1.6004e+02,  1.3019e+02,
         1.4195e+01,  2.4137e+02,  5.2065e+01,  2.0826e+01,  1.5605e+01,
         2.0909e+02,  1.3755e+01,  1.5605e+01,  2.7889e+01,  3.9520e+00,
         3.4183e+01,  1.4195e+01,  1.3755e+01,  1.4195e+01,  6.6526e+01,
         7.8416e+01,  6.6526e+01,  1.2314e+00,  2.5040e+01,  6.6526e+01,
         1.6004e+02,  5.2065e+01,  1.5605e+01,  1.3755e+01,  1.0930e+02,
         5.9282e+01,  2.5603e+02,  2.3176e+01,  6.6898e+01,  6.1139e+01,
         5.3547e+00,  2.4546e+01,  6.1139e+01,  5.9106e+01,  1.5605e+01,
         2.0140e+01,  7.8416e+01,  1.9733e-04,  1.3389e+02,  1.2800e+02,
         3.9520e+00,  2.4466e+00,  1.4058e+01,  9.9645e+00,  7.9155e+01,
         2.5603e+02, -3.1178e-01,  1.7617e+01,  6.6526e+01,  1.3389e+02,
         1.4058e+01,  1.4195e+01,  1.8545e+01,  1.3389e+02,  6.6898e+01,
         2.0140e+01,  1.7617e+01,  2.6128e+00,  1.8545e+01,  2.4466e+00,
         7.9155e+01,  1.3019e+02,  2.0140e+01,  1.5034e+01,  1.6004e+02,
         5.5210e+01,  2.5607e+02,  1.0930e+02,  1.3019e+02,  6.8941e+01,
         5.2065e+01,  1.9624e+02,  1.3755e+01,  1.6004e+02,  6.6526e+01,
         2.5040e+01,  1.4058e+01,  1.5034e+01,  2.5040e+01,  1.3755e+01,
         1.6004e+02,  6.6898e+01,  3.3437e+01,  2.4137e+02,  5.9282e+01,
         1.6004e+02,  1.3755e+01,  5.5210e+01,  1.5605e+01,  2.0140e+01,
         2.4546e+01,  1.3389e+02,  6.6526e+01,  6.6898e+01,  3.3437e+01,
         1.9624e+02,  1.5034e+01,  2.5333e+01,  2.0826e+01,  6.6526e+01,
         5.9282e+01,  2.3176e+01,  2.3176e+01,  1.6004e+02,  1.4058e+01,
         2.5607e+02,  6.6898e+01,  6.8941e+01,  1.6004e+02,  1.5745e+01,
         1.3755e+01,  2.5607e+02,  2.5603e+02,  6.6898e+01,  7.8416e+01,
         5.9282e+01,  2.4137e+02,  2.5601e+02,  1.2800e+02,  5.2065e+01,
         5.2065e+01,  1.3755e+01,  1.5034e+01,  7.2775e+01,  2.8778e+01,
         3.9263e+00,  1.3389e+02,  2.5040e+01,  7.8416e+01,  1.4195e+01,
         1.3019e+02,  7.8416e+01,  1.8545e+01,  6.8941e+01,  1.6004e+02,
         1.2800e+02,  2.0909e+02,  1.4154e+01,  2.7889e+01,  5.5210e+01,
         1.3389e+02,  1.3019e+02,  2.4466e+00,  5.5210e+01,  1.6004e+02,
         6.6526e+01,  5.9282e+01,  1.9624e+02,  1.8545e+01,  5.9282e+01,
         1.5605e+01,  5.2065e+01,  2.0140e+01,  1.4058e+01,  1.0930e+02,
         6.1139e+01,  3.3437e+01,  1.5605e+01,  2.5607e+02,  6.6898e+01,
         1.3755e+01,  5.5210e+01,  2.0140e+01,  1.5605e+01,  3.3437e+01,
         2.5040e+01,  6.1139e+01,  5.9282e+01,  2.5602e+02,  2.4466e+00,
         2.5040e+01,  5.9106e+01,  5.2065e+01,  2.5607e+02,  2.4137e+02,
         5.2065e+01,  1.3755e+01,  1.2800e+02,  3.3437e+01,  2.0140e+01,
         6.6526e+01,  2.3176e+01,  1.2314e+00,  2.5607e+02,  7.9155e+01,
         1.5034e+01,  1.6004e+02,  2.4466e+00,  3.3437e+01,  1.5034e+01,
         1.8545e+01,  2.3176e+01,  6.8997e-01,  1.2800e+02,  6.6898e+01,
         2.6128e+00,  1.4058e+01,  3.3437e+01,  1.4058e+01,  2.0140e+01,
         2.0140e+01,  6.1139e+01,  1.3019e+02,  6.1139e+01,  4.8536e+00,
         1.4058e+01,  1.5605e+01,  1.4195e+01,  2.0140e+01,  3.4183e+01,
         1.5034e+01,  2.4137e+02,  5.5210e+01,  5.2065e+01,  2.8778e+01,
         2.3176e+01,  1.4195e+01,  1.3755e+01,  1.3846e+01,  1.3755e+01,
         1.6004e+02,  1.4195e+01,  1.6004e+02,  1.2803e+02,  9.9645e+00,
         3.9551e+00,  2.4137e+02,  2.8778e+01,  1.6004e+02,  3.3094e+00,
         2.5607e+02,  1.8545e+01,  1.3755e+01,  1.3019e+02,  2.0909e+02,
         1.3389e+02,  2.0140e+01,  7.8416e+01,  2.4466e+00,  1.3755e+01,
         1.3755e+01,  2.0826e+01,  2.0909e+02,  5.2065e+01,  5.2065e+01,
         3.0178e+00,  5.9282e+01,  2.4137e+02,  6.1139e+01,  1.4058e+01,
         1.5605e+01,  1.3389e+02,  6.6526e+01,  2.5607e+02,  9.9645e+00,
         2.4466e+00,  1.5605e+01,  1.2800e+02,  5.9282e+01,  5.2065e+01,
         5.9282e+01,  6.6898e+01,  4.3125e+00,  5.5210e+01,  1.5745e+01,
         1.0930e+02,  1.8545e+01,  2.5333e+01,  1.1595e+02,  1.3019e+02,
         5.9106e+01,  1.3389e+02,  2.5607e+02,  1.8545e+01,  6.1139e+01,
         5.5210e+01,  9.9645e+00,  1.6004e+02,  1.4195e+01,  1.9624e+02,
         1.8545e+01,  1.4195e+01,  7.8416e+01,  1.5034e+01,  2.0140e+01,
         7.8416e+01,  5.2065e+01,  6.1139e+01,  3.4183e+01,  5.5210e+01,
         2.0909e+02,  1.3755e+01,  1.4058e+01,  1.4195e+01,  1.3019e+02,
         5.5210e+01,  3.3437e+01,  1.5605e+01,  2.6128e+00,  1.8545e+01,
         2.0140e+01,  2.5607e+02,  5.9282e+01,  9.9645e+00,  1.0350e+02,
         1.4058e+01,  6.8941e+01,  1.3389e+02,  6.6526e+01,  1.5605e+01,
         2.5040e+01,  5.5210e+01,  2.0909e+02,  2.4137e+02,  2.3176e+01,
         1.0350e+02,  1.2314e+00,  2.4546e+01,  2.6128e+00,  2.4137e+02,
         1.6004e+02,  5.2065e+01,  6.6526e+01,  2.4466e+00,  1.0930e+02,
         2.4137e+02,  1.2800e+02,  2.3496e+01,  1.7617e+01,  2.4466e+00,
         7.8416e+01,  6.8941e+01,  2.3176e+01,  3.0178e+00,  6.1139e+01,
         5.9106e+01,  1.5605e+01,  1.2800e+02,  3.0178e+00,  1.2800e+02,
         1.6004e+02,  5.2065e+01,  1.4058e+01,  5.9282e+01,  7.8416e+01,
         3.3094e+00,  3.9263e+00,  1.2800e+02,  3.0178e+00,  7.8416e+01,
         6.6526e+01,  3.0178e+00,  2.7889e+01,  6.8941e+01,  3.3094e+00,
         6.6898e+01,  6.1139e+01,  1.9624e+02,  1.5745e+01,  1.5605e+01,
         6.6526e+01,  1.3019e+02,  7.9155e+01,  7.8416e+01,  6.8941e+01,
         1.0930e+02,  1.4058e+01,  1.3755e+01,  6.1139e+01,  9.9645e+00,
         6.8941e+01,  6.8941e+01,  1.2800e+02,  6.1139e+01,  2.0140e+01,
         7.9155e+01,  5.5210e+01], device='cuda:0', requires_grad=True)
PARAM: torch.Size([512]) Parameter containing:
tensor([0.9505, 0.8842, 1.0603, 0.9505, 0.9276, 1.2002, 1.0169, 1.2197, 1.1037,
        0.9505, 0.8480, 1.0337, 0.8842, 0.8480, 1.4318, 1.0338, 1.4318, 0.9856,
        1.2197, 0.7950, 1.0677, 1.0603, 1.7890, 0.9856, 1.2197, 0.7937, 1.0701,
        0.7950, 1.6367, 0.7950, 0.8768, 0.7949, 1.7890, 0.9155, 0.9505, 0.7937,
        1.1037, 1.7022, 0.9856, 0.9505, 0.8961, 0.7925, 1.1859, 1.2122, 1.1025,
        0.9856, 1.1037, 1.3243, 1.2197, 1.0537, 0.9156, 0.9856, 0.7949, 0.5331,
        1.4318, 0.7925, 1.2653, 0.6357, 1.1859, 1.7890, 1.3243, 0.7925, 0.9155,
        0.7949, 1.0701, 0.7937, 1.2653, 1.4318, 0.7937, 1.3243, 0.9156, 0.8456,
        0.7937, 1.4318, 0.8456, 0.9156, 0.9856, 0.8047, 1.3243, 1.0590, 1.0014,
        1.0229, 1.7890, 1.2002, 0.7925, 1.2197, 0.7925, 1.0603, 0.9156, 1.2122,
        0.9856, 0.9856, 1.0769, 0.7913, 0.7937, 1.7022, 0.7950, 0.8480, 1.7022,
        0.9156, 0.7949, 1.7890, 0.8480, 0.9505, 0.9106, 1.2197, 1.1659, 0.8480,
        1.0677, 1.0701, 0.8456, 1.7022, 1.1037, 0.8480, 0.8456, 1.4318, 1.1859,
        1.1037, 1.0701, 0.9505, 0.7937, 0.7937, 0.7937, 0.8456, 0.9106, 0.9856,
        0.9505, 0.9276, 0.7937, 0.8456, 1.0590, 0.7937, 1.7890, 1.7890, 1.2197,
        0.7925, 1.4318, 1.0677, 0.9276, 0.7950, 1.2002, 0.7949, 0.7950, 0.5923,
        0.8468, 0.6357, 0.7925, 0.7949, 0.7925, 0.8529, 0.9856, 0.8529, 1.1743,
        1.0590, 0.8529, 1.7890, 1.0677, 0.7950, 0.7949, 0.9155, 1.0701, 1.2122,
        1.0603, 1.0170, 1.1859, 1.5172, 0.5947, 1.1859, 0.9204, 0.7950, 0.8456,
        0.9856, 1.0769, 1.7022, 0.9106, 0.8468, 1.0549, 0.7937, 1.0229, 0.8842,
        1.2122, 0.9803, 1.1037, 0.8529, 1.7022, 0.7937, 0.7925, 0.7913, 1.7022,
        1.0170, 0.8456, 1.1037, 1.0169, 0.7913, 1.0549, 0.8842, 1.2197, 0.8456,
        0.7937, 1.7890, 0.9505, 1.6876, 0.9155, 1.2197, 0.9156, 1.0677, 1.2653,
        0.7949, 1.7890, 0.8529, 1.0590, 0.7937, 0.7937, 1.0590, 0.7949, 1.7890,
        1.0170, 1.3243, 1.4318, 1.0701, 1.7890, 0.7949, 0.9505, 0.7950, 0.8456,
        0.5947, 1.7022, 0.8529, 1.0170, 1.3243, 1.2653, 0.7937, 0.5899, 0.9276,
        0.8529, 1.0701, 1.0603, 1.0603, 1.7890, 0.7937, 1.6876, 1.0170, 0.9156,
        1.7890, 1.1025, 0.7949, 1.6876, 1.2122, 1.0170, 0.9856, 1.0701, 1.4318,
        1.5788, 0.9106, 1.0677, 1.0677, 0.7949, 0.7937, 0.9494, 0.5874, 0.9848,
        1.7022, 1.0590, 0.9856, 0.7925, 1.2197, 0.9856, 0.7913, 0.9156, 1.7890,
        0.8961, 1.2002, 0.7937, 0.5923, 0.9505, 1.7022, 1.2197, 1.0549, 0.9505,
        1.7890, 0.8529, 1.0701, 1.2653, 0.7913, 1.0701, 0.7950, 1.0677, 0.8456,
        0.7937, 0.9155, 1.1859, 1.3243, 0.7950, 1.6876, 1.0170, 0.7949, 0.9505,
        0.8456, 0.7950, 1.3243, 1.0590, 1.1859, 1.0701, 1.5981, 1.0549, 1.0590,
        0.9204, 1.0677, 1.6876, 1.4318, 1.0677, 0.7949, 0.8961, 1.3243, 0.8456,
        0.8529, 1.0603, 1.1743, 1.6876, 0.8842, 0.7937, 1.7890, 1.0549, 1.3243,
        0.7937, 0.7913, 1.0603, 0.9846, 0.9106, 1.0170, 1.0169, 0.7937, 1.3243,
        0.7937, 0.8456, 0.8456, 1.1859, 1.2197, 1.1859, 1.5159, 0.7937, 0.7950,
        0.7925, 0.8456, 0.6357, 0.7937, 1.4318, 0.9505, 1.0677, 0.5874, 1.0603,
        0.7925, 0.7949, 0.7925, 0.7949, 1.7890, 0.7925, 1.7890, 1.0338, 1.0229,
        0.8474, 1.4318, 0.5874, 1.7890, 0.7556, 1.6876, 0.7913, 0.7949, 1.2197,
        1.2002, 1.7022, 0.8456, 0.9856, 1.0549, 0.7949, 0.7949, 0.9276, 1.2002,
        1.0677, 1.0677, 0.5331, 1.0701, 1.4318, 1.1859, 0.7937, 0.7950, 1.7022,
        0.8529, 1.6876, 1.0229, 1.0549, 0.7950, 0.8961, 1.0701, 1.0677, 1.0701,
        1.0170, 0.8768, 0.9505, 1.1025, 0.9155, 0.7913, 0.5899, 0.8480, 1.2197,
        0.9204, 1.7022, 1.6876, 0.7913, 1.1859, 0.9505, 1.0229, 1.7890, 0.7925,
        1.2653, 0.7913, 0.7925, 0.9856, 0.7937, 0.8456, 0.9856, 1.0677, 1.1859,
        0.6357, 0.9505, 1.2002, 0.7949, 0.7937, 0.7925, 1.2197, 0.9505, 1.3243,
        0.7950, 1.0169, 0.7913, 0.8456, 1.6876, 1.0701, 1.0229, 1.0338, 0.7937,
        0.9156, 1.7022, 0.8529, 0.7950, 1.0590, 0.9505, 1.2002, 1.4318, 1.0603,
        1.0338, 1.1743, 0.5947, 1.0169, 1.4318, 1.7890, 1.0677, 0.8529, 1.0549,
        0.9155, 1.4318, 0.9106, 1.0156, 1.1037, 1.0549, 0.9856, 0.9156, 1.0603,
        0.5331, 1.1859, 0.9204, 0.7950, 0.9106, 0.5331, 0.9106, 1.7890, 1.0677,
        0.7937, 1.0701, 0.9856, 0.7556, 0.9848, 0.9106, 0.5331, 0.9856, 0.8529,
        0.5331, 0.5923, 0.9156, 0.7556, 1.0170, 1.1859, 1.2653, 1.1025, 0.7950,
        0.8529, 1.2197, 0.8842, 0.9856, 0.9156, 0.9155, 0.7937, 0.7949, 1.1859,
        1.0229, 0.9156, 0.9156, 0.9106, 1.1859, 0.8456, 0.8842, 0.9505],
       device='cuda:0', requires_grad=True)
PARAM: torch.Size([512]) Parameter containing:
tensor([-60000., -60000., -60000., -60000., -60000., -60000., -60000., -60000.,
        -60000., -60000., -60000., -60000., -60000., -60000., -60000., -60000.,
        -60000., -60000., -60000., -60000., -60000., -60000., -60000., -60000.,
        -60000., -60000., -60000., -60000., -60000., -60000., -60000., -60000.,
        -60000., -60000., -60000., -60000., -60000., -60000., -60000., -60000.,
        -60000., -60000., -60000., -60000., -60000., -60000., -60000., -60000.,
        -60000., -60000., -60000., -60000., -60000., -60000., -60000., -60000.,
        -60000., -60000., -60000., -60000., -60000., -60000., -60000., -60000.,
        -60000., -60000., -60000., -60000., -60000., -60000., -60000., -60000.,
        -60000., -60000., -60000., -60000., -60000., -60000., -60000., -60000.,
        -60000., -60000., -60000., -60000., -60000., -60000., -60000., -60000.,
        -60000., -60000., -60000., -60000., -60000., -60000., -60000., -60000.,
        -60000., -60000., -60000., -60000., -60000., -60000., -60000., -60000.,
        -60000., -60000., -60000., -60000., -60000., -60000., -60000., -60000.,
        -60000., -60000., -60000., -60000., -60000., -60000., -60000., -60000.,
        -60000., -60000., -60000., -60000., -60000., -60000., -60000., -60000.,
        -60000., -60000., -60000., -60000., -60000., -60000., -60000., -60000.,
        -60000., -60000., -60000., -60000., -60000., -60000., -60000., -60000.,
        -60000., -60000., -60000., -60000., -60000., -60000., -60000., -60000.,
        -60000., -60000., -60000., -60000., -60000., -60000., -60000., -60000.,
        -60000., -60000., -60000., -60000., -60000., -60000., -60000., -60000.,
        -60000., -60000., -60000., -60000., -60000., -60000., -60000., -60000.,
        -60000., -60000., -60000., -60000., -60000., -60000., -60000., -60000.,
        -60000., -60000., -60000., -60000., -60000., -60000., -60000., -60000.,
        -60000., -60000., -60000., -60000., -60000., -60000., -60000., -60000.,
        -60000., -60000., -60000., -60000., -60000., -60000., -60000., -60000.,
        -60000., -60000., -60000., -60000., -60000., -60000., -60000., -60000.,
        -60000., -60000., -60000., -60000., -60000., -60000., -60000., -60000.,
        -60000., -60000., -60000., -60000., -60000., -60000., -60000., -60000.,
        -60000., -60000., -60000., -60000., -60000., -60000., -60000., -60000.,
        -60000., -60000., -60000., -60000., -60000., -60000., -60000., -60000.,
        -60000., -60000., -60000., -60000., -60000., -60000., -60000., -60000.,
        -60000., -60000., -60000., -60000., -60000., -60000., -60000., -60000.,
        -60000., -60000., -60000., -60000., -60000., -60000., -60000., -60000.,
        -60000., -60000., -60000., -60000., -60000., -60000., -60000., -60000.,
        -60000., -60000., -60000., -60000., -60000., -60000., -60000., -60000.,
        -60000., -60000., -60000., -60000., -60000., -60000., -60000., -60000.,
        -60000., -60000., -60000., -60000., -60000., -60000., -60000., -60000.,
        -60000., -60000., -60000., -60000., -60000., -60000., -60000., -60000.,
        -60000., -60000., -60000., -60000., -60000., -60000., -60000., -60000.,
        -60000., -60000., -60000., -60000., -60000., -60000., -60000., -60000.,
        -60000., -60000., -60000., -60000., -60000., -60000., -60000., -60000.,
        -60000., -60000., -60000., -60000., -60000., -60000., -60000., -60000.,
        -60000., -60000., -60000., -60000., -60000., -60000., -60000., -60000.,
        -60000., -60000., -60000., -60000., -60000., -60000., -60000., -60000.,
        -60000., -60000., -60000., -60000., -60000., -60000., -60000., -60000.,
        -60000., -60000., -60000., -60000., -60000., -60000., -60000., -60000.,
        -60000., -60000., -60000., -60000., -60000., -60000., -60000., -60000.,
        -60000., -60000., -60000., -60000., -60000., -60000., -60000., -60000.,
        -60000., -60000., -60000., -60000., -60000., -60000., -60000., -60000.,
        -60000., -60000., -60000., -60000., -60000., -60000., -60000., -60000.,
        -60000., -60000., -60000., -60000., -60000., -60000., -60000., -60000.,
        -60000., -60000., -60000., -60000., -60000., -60000., -60000., -60000.,
        -60000., -60000., -60000., -60000., -60000., -60000., -60000., -60000.,
        -60000., -60000., -60000., -60000., -60000., -60000., -60000., -60000.,
        -60000., -60000., -60000., -60000., -60000., -60000., -60000., -60000.,
        -60000., -60000., -60000., -60000., -60000., -60000., -60000., -60000.,
        -60000., -60000., -60000., -60000., -60000., -60000., -60000., -60000.,
        -60000., -60000., -60000., -60000., -60000., -60000., -60000., -60000.,
        -60000., -60000., -60000., -60000., -60000., -60000., -60000., -60000.,
        -60000., -60000., -60000., -60000., -60000., -60000., -60000., -60000.,
        -60000., -60000., -60000., -60000., -60000., -60000., -60000., -60000.,
        -60000., -60000., -60000., -60000., -60000., -60000., -60000., -60000.,
        -60000., -60000., -60000., -60000., -60000., -60000., -60000., -60000.],
       device='cuda:0', requires_grad=True)
PARAM: torch.Size([128, 512]) Parameter containing:
tensor([[-1., -1., -1.,  ...,  1.,  1.,  1.],
        [-1., -1., -1.,  ..., -1.,  1., -1.],
        [ 1., -1., -1.,  ..., -1., -1., -1.],
        ...,
        [ 1., -1., -1.,  ..., -1., -1., -1.],
        [-1.,  1., -1.,  ...,  1.,  1.,  1.],
        [ 1.,  1., -1.,  ...,  1.,  1.,  1.]], device='cuda:0',
       requires_grad=True)
PARAM: torch.Size([128]) Parameter containing:
tensor([ 1.4058e+01,  1.7617e+01,  1.5605e+01,  5.5210e+01,  3.0178e+00,
         2.3176e+01,  5.9282e+01,  9.9645e+00,  1.5974e+00,  1.6004e+02,
         7.8416e+01,  1.3019e+02,  1.4195e+01,  1.8545e+01, -1.7931e-05,
         6.1139e+01,  4.3125e+00,  4.1038e+00,  3.9263e+00,  1.7617e+01,
         9.9645e+00,  2.3176e+01,  6.1139e+01,  1.7617e+01,  2.0140e+01,
         5.9282e+01,  6.8997e-01,  1.2314e+00,  3.0178e+00,  3.3094e+00,
         2.0826e+01,  9.9645e+00,  7.8416e+01,  2.6128e+00,  1.2800e+02,
         5.5210e+01,  2.3496e+01,  3.9263e+00,  6.6526e+01,  1.3389e+02,
         2.4466e+00,  2.0140e+01,  1.3019e+02,  1.5745e+01,  1.5745e+01,
         2.0826e+01,  1.5034e+01,  1.4195e+01,  5.5210e+01,  6.6898e+01,
         6.1139e+01,  5.9282e+01,  4.5970e+01,  2.3176e+01,  1.4058e+01,
         1.4195e+01,  1.2314e+00,  2.3176e+01,  1.7617e+01, -3.1182e-01,
         6.8941e+01,  1.3019e+02,  1.4058e+01,  2.4135e+01,  3.3094e+00,
         7.8416e+01,  1.3019e+02,  9.9645e+00,  4.6936e-01,  2.4466e+00,
         6.1139e+01,  2.0826e+01,  1.3755e+01,  2.4466e+00,  6.8941e+01,
         2.4466e+00,  1.5745e+01,  9.9645e+00,  3.3437e+01,  1.9733e-04,
         2.0140e+01,  1.5745e+01,  9.9645e+00,  6.1139e+01,  5.9282e+01,
         7.9155e+01,  1.4195e+01,  3.3437e+01,  7.9155e+01,  1.5974e+00,
         1.3755e+01,  3.9520e+00,  4.1038e+00,  7.8416e+01,  1.8545e+01,
         4.5598e+00,  1.4058e+01,  2.5040e+01,  1.3755e+01,  3.9520e+00,
         2.5603e+02,  1.4058e+01,  6.8997e-01,  9.9645e+00,  1.2800e+02,
         3.9263e+00,  6.1139e+01,  6.6526e+01,  4.1038e+00,  1.4154e+01,
         1.2800e+02,  3.4183e+01,  9.9645e+00,  2.5040e+01,  1.4195e+01,
         1.5605e+01,  2.0826e+01,  5.5210e+01,  5.5210e+01,  2.5040e+01,
         2.4137e+02,  1.4195e+01,  5.9282e+01,  1.5605e+01,  4.6936e-01,
         7.8416e+01,  3.3437e+01,  5.2065e+01], device='cuda:0',
       requires_grad=True)
PARAM: torch.Size([128]) Parameter containing:
tensor([0.7937, 1.1037, 0.7950, 0.9505, 0.5331, 1.0603, 1.0701, 1.0229, 0.9261,
        1.7890, 0.9856, 1.2197, 0.7925, 0.7913, 1.0179, 1.1859, 0.8768, 0.9830,
        0.9848, 1.1037, 1.0229, 1.0603, 1.1859, 1.1037, 0.8456, 1.0701, 0.9846,
        1.1743, 0.5331, 0.7556, 0.9276, 1.0229, 0.9856, 1.0169, 0.9106, 0.9505,
        1.0156, 0.9848, 0.8529, 1.7022, 1.0549, 0.8456, 1.2197, 1.1025, 1.1025,
        0.9276, 0.7937, 0.7925, 0.9505, 1.0170, 1.1859, 1.0701, 0.9663, 1.0603,
        0.7937, 0.7925, 1.1743, 1.0603, 1.1037, 0.9804, 0.9156, 1.2197, 0.7937,
        0.9263, 0.7556, 0.9856, 1.2197, 1.0229, 0.9291, 1.0549, 1.1859, 0.9276,
        0.7949, 1.0549, 0.9156, 1.0549, 1.1025, 1.0229, 1.3243, 1.0769, 0.8456,
        1.1025, 1.0229, 1.1859, 1.0701, 0.8842, 0.7925, 1.3243, 0.8842, 0.9261,
        0.7949, 0.8468, 0.9830, 0.9856, 0.7913, 0.8791, 0.7937, 1.0590, 0.7949,
        0.8468, 1.2122, 0.7937, 0.9846, 1.0229, 1.0338, 0.9848, 1.1859, 0.8529,
        0.9830, 0.7937, 0.9106, 0.6357, 1.0229, 1.0590, 0.7925, 0.7950, 0.9276,
        0.9505, 0.9505, 1.0590, 1.4318, 0.7925, 1.0701, 0.7950, 0.9291, 0.9856,
        1.3243, 1.0677], device='cuda:0', requires_grad=True)
PARAM: torch.Size([128]) Parameter containing:
tensor([-60000., -60000., -60000., -60000., -60000., -60000., -60000., -60000.,
        -60000., -60000., -60000., -60000., -60000., -60000., -60000., -60000.,
        -60000., -60000., -60000., -60000., -60000., -60000., -60000., -60000.,
        -60000., -60000., -60000., -60000., -60000., -60000., -60000., -60000.,
        -60000., -60000., -60000., -60000., -60000., -60000., -60000., -60000.,
        -60000., -60000., -60000., -60000., -60000., -60000., -60000., -60000.,
        -60000., -60000., -60000., -60000., -60000., -60000., -60000., -60000.,
        -60000., -60000., -60000., -60000., -60000., -60000., -60000., -60000.,
        -60000., -60000., -60000., -60000., -60000., -60000., -60000., -60000.,
        -60000., -60000., -60000., -60000., -60000., -60000., -60000., -60000.,
        -60000., -60000., -60000., -60000., -60000., -60000., -60000., -60000.,
        -60000., -60000., -60000., -60000., -60000., -60000., -60000., -60000.,
        -60000., -60000., -60000., -60000., -60000., -60000., -60000., -60000.,
        -60000., -60000., -60000., -60000., -60000., -60000., -60000., -60000.,
        -60000., -60000., -60000., -60000., -60000., -60000., -60000., -60000.,
        -60000., -60000., -60000., -60000., -60000., -60000., -60000., -60000.],
       device='cuda:0', requires_grad=True)
PARAM: torch.Size([10, 128]) Parameter containing:
tensor([[ 1.,  1., -1.,  ...,  1.,  1., -1.],
        [ 1., -1., -1.,  ...,  1., -1., -1.],
        [ 1., -1., -1.,  ...,  1.,  1., -1.],
        ...,
        [ 1., -1.,  1.,  ...,  1.,  1., -1.],
        [ 1., -1.,  1.,  ...,  1., -1., -1.],
        [-1., -1., -1.,  ...,  1.,  1.,  1.]], device='cuda:0',
       requires_grad=True)
PARAM: torch.Size([10]) Parameter containing:
tensor([-1.2126,  4.9188, -9.2046, -3.1782,  2.7760,  2.6989, -7.2115,  0.8443,
        10.7764, -1.2072], device='cuda:0', requires_grad=True)
Accuracy of the network on the 10000 test images: 11.35 %
