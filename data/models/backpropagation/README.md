### Model1

### Model2

Start training model2
Epoch [1/30], Loss: 6.2281
Epoch [2/30], Loss: 4.4330
Epoch [3/30], Loss: 5.2891
Epoch [4/30], Loss: 5.1991
Epoch [5/30], Loss: 4.4700
Epoch [6/30], Loss: 4.6325
Epoch [7/30], Loss: 4.4030
Epoch [8/30], Loss: 4.6550
Epoch [9/30], Loss: 4.2664
Epoch [10/30], Loss: 3.9064
Epoch [11/30], Loss: 4.6729
Epoch [12/30], Loss: 3.8994
Epoch [13/30], Loss: 4.0667
Epoch [14/30], Loss: 4.1052
Epoch [15/30], Loss: 3.9673
Epoch [16/30], Loss: 3.8135
Epoch [17/30], Loss: 3.4610
Epoch [18/30], Loss: 3.9986
Epoch [19/30], Loss: 3.2736
Epoch [20/30], Loss: 3.2893
Epoch [21/30], Loss: 3.5059
Epoch [22/30], Loss: 3.6099
Epoch [23/30], Loss: 3.3305
Epoch [24/30], Loss: 3.4650
Epoch [25/30], Loss: 3.5107
Epoch [26/30], Loss: 3.5953
Epoch [27/30], Loss: 3.5075
Epoch [28/30], Loss: 3.1222
Epoch [29/30], Loss: 3.2397
Epoch [30/30], Loss: 3.2709
End training model2 in 88.38049943447113 minutes or 1.4730083239078522 hours
----------------------------------------------------------------
        Layer (type)               Output Shape         Param #
================================================================
BinaryInternalLinear-1                   [-1, 16]       3,211,280
       BatchNorm1d-2                   [-1, 16]              32
        Activation-3                   [-1, 16]               0
      BinaryLinear-4                   [-1, 16]               0
BinaryInternalLinear-5                   [-1, 10]             170
BinaryLinearOutput-6                   [-1, 10]               0
================================================================
Total params: 3,211,482
Trainable params: 3,211,482
Non-trainable params: 0
----------------------------------------------------------------
Input size (MB): 0.77
Forward/backward pass size (MB): 0.00
Params size (MB): 12.25
Estimated Total Size (MB): 13.02
----------------------------------------------------------------
PARAM: torch.Size([16, 200704]) Parameter containing:
tensor([[-1., -1.,  1.,  ..., -1., -1.,  1.],
        [-1.,  1.,  1.,  ...,  1.,  1.,  1.],
        [-1.,  1., -1.,  ...,  1.,  1.,  1.],
        ...,
        [-1.,  1.,  1.,  ..., -1.,  1.,  1.],
        [ 1., -1.,  1.,  ..., -1., -1.,  1.],
        [-1.,  1., -1.,  ..., -1.,  1., -1.]], requires_grad=True)
PARAM: torch.Size([16]) Parameter containing:
tensor([8.1018e-13, 7.0123e-11, 1.4077e-12, 3.6801e-12, 2.6604e-13, 4.2673e-12,
        1.7851e-11, 1.2945e-12, 2.1592e-11, 1.2838e-12, 1.2553e-11, 3.9455e-12,
        5.6927e-12, 2.4896e-11, 1.5966e-11, 6.8053e-12], requires_grad=True)
PARAM: torch.Size([16]) Parameter containing:
tensor([1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,
        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000],
       requires_grad=True)
PARAM: torch.Size([16]) Parameter containing:
tensor([-1530., -1530., -1530., -1530., -1530., -1530., -1530., -1530., -1530.,
        -1530., -1530., -1530., -1530., -1530., -1530., -1530.],
       requires_grad=True)
PARAM: torch.Size([10, 16]) Parameter containing:
tensor([[ 1.,  1.,  1.,  1., -1., -1., -1., -1., -1., -1.,  1., -1.,  1.,  1.,
         -1.,  1.],
        [-1., -1.,  1.,  1.,  1., -1.,  1., -1.,  1., -1.,  1., -1.,  1.,  1.,
         -1., -1.],
        [ 1.,  1.,  1., -1.,  1., -1.,  1., -1.,  1., -1.,  1., -1., -1., -1.,
          1., -1.],
        [ 1., -1.,  1.,  1., -1.,  1., -1.,  1., -1., -1., -1., -1., -1.,  1.,
          1.,  1.],
        [-1.,  1.,  1., -1., -1.,  1., -1., -1.,  1., -1., -1.,  1., -1.,  1.,
          1.,  1.],
        [ 1.,  1.,  1., -1., -1.,  1., -1., -1.,  1.,  1., -1.,  1., -1., -1.,
         -1.,  1.],
        [-1., -1.,  1., -1., -1., -1.,  1.,  1., -1.,  1.,  1., -1.,  1.,  1.,
          1., -1.],
        [-1., -1.,  1., -1., -1.,  1., -1., -1.,  1.,  1.,  1., -1.,  1.,  1.,
          1., -1.],
        [-1., -1., -1., -1.,  1.,  1., -1.,  1.,  1.,  1.,  1.,  1., -1.,  1.,
          1., -1.],
        [-1.,  1.,  1.,  1., -1., -1., -1.,  1.,  1., -1., -1.,  1.,  1.,  1.,
         -1., -1.]], requires_grad=True)
PARAM: torch.Size([10]) Parameter containing:
tensor([-0.0068,  0.0799, -0.0191,  0.0104, -0.0093, -0.0493, -0.0089,  0.0291,
        -0.0223, -0.0036], requires_grad=True)
Accuracy of the network on the 10000 test images: 11.35 %
